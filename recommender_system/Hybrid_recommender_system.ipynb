{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8064b824",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "986f0a5f",
   "metadata": {},
   "source": [
    "In modern recommender systems, effectively utilizing user feedback is crucial for enhancing recommendation quality and user experience. Feedback is categorized into explicit and implicit types. Explicit feedback, such as ratings and likes, directly indicates user preferences, while implicit feedback is inferred from behaviors like clicks and purchase history.\n",
    "\n",
    "Handling these feedback types requires different approaches. Explicit feedback should not treat missing values as zero, as this may misrepresent user sentiment. Conversely, with implicit feedback, missing values can often be filled with zeros, indicating potential disinterest.\n",
    "\n",
    "Sparsity in user ratings poses challenges for traditional algorithms like K-Nearest Neighbors (KNN). Thus, addressing sparse data is vital for building effective recommendation models. While accuracy is a key metric for evaluating recommender systems, secondary metrics like diversity (providing varied recommendations) and serendipity (offering unexpected yet relevant suggestions) also enhance user engagement and satisfaction.\n",
    "\n",
    "This project will develop a hybrid recommender system using a meta-level approach, combining content-based and collaborative filtering. Content-based filtering helps mitigate the cold-start problem by leveraging item features to make initial recommendations. By extracting movie details from IMDb, the system will group users with similar preferences based on content features and then apply collaborative filtering to make predictions.\n",
    "\n",
    "This customized approach, termed “collaboration via content,” enhances traditional collaborative filtering by incorporating content data to identify similar users. While effective for recommending movies within specific genres, this strategy can also diversify recommendations in industries aiming to encourage users to explore new products, particularly during business expansions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62ae8cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "# Suppress all warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re \n",
    "from sklearn.model_selection import train_test_split\n",
    "# from surprise import Reader, Dataset, SVD, evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c81a4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_columns = ['movieId', 'title', 'genres']\n",
    "ratings_columns = ['userId','movieId', 'rating', 'timestamp']\n",
    "\n",
    "movies_df = pd.read_csv('/Users/top/Documents/GitHub/data_science_projects/movielens/ml-10M100K/movies.dat', sep='::', names=movies_columns, engine='python')\n",
    "ratings_df = pd.read_csv('/Users/top/Documents/GitHub/data_science_projects/movielens/ml-10M100K/ratings.dat', sep='::', names=ratings_columns, engine='python')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e784d265",
   "metadata": {},
   "source": [
    "# TLDR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f86384",
   "metadata": {},
   "source": [
    "1. Content-Based Filtering: This approach utilizes item characteristics to provide recommendations, effectively addressing the cold-start problem by suggesting similar items based on user preferences, even with limited interaction history.\n",
    "\n",
    "2. Complex Models and Overfitting: While sophisticated models can be appealing, they risk overfitting, leading to poor generalization on unseen data. Balancing model complexity with regularization techniques and validation is essential for robust performance.\n",
    "\n",
    "3. Matrix Factorization and Gradient Descent: These techniques enhance collaborative filtering by learning user-item interactions without filling missing values with zeros, which can introduce bias. Gradient descent optimizes latent factors, resulting in more accurate and personalized recommendations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8f9c21",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9bb2b9f",
   "metadata": {},
   "source": [
    "To handle bias in ratings, where some users might give consistently high or low ratings, I will use centered ratings. This means adjusting each user's rating by subtracting their average rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5660731",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_df['centered_rating'] = ratings_df['rating'] - ratings_df.groupby('userId')['rating'].transform('mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "267e433f",
   "metadata": {},
   "outputs": [],
   "source": [
    "genre=[]\n",
    "\n",
    "for num in range(0, len(movies_df)):\n",
    "    key = movies_df.iloc[num]['title']\n",
    "    value = movies_df.iloc[num]['genres'].split('|')\n",
    "    genre.append(value)\n",
    "    \n",
    "movies_df['genres'] = genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c526abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = re.compile(r\"(?:\\((\\d{4})\\))?\\s*$\")\n",
    "years=[]\n",
    "for movies in movies_df['title']:\n",
    "     m = p.search(movies)\n",
    "     year = m.group(1)\n",
    "     years.append(year)  \n",
    "movies_df['year']=years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0eed01e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_name=[]\n",
    "raw=[]\n",
    "\n",
    "for movies in movies_df['title']:\n",
    "     m = p.search(movies)\n",
    "     year = m.group(0)\n",
    "     new=re.split(year, movies)\n",
    "     raw.append(new)  \n",
    "for i in range(len(raw)):\n",
    "    movies_name.append(raw[i][0][:-2].title())\n",
    "    \n",
    "movies_df['title'] = movies_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1fc14536",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df['features'] = (\n",
    "    movies_df['title'] + \n",
    "    ' ' + movies_df['genres'].apply(lambda x: ' '.join(x)) + \n",
    "    ' ' + movies_df['year'].astype(str)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c90977",
   "metadata": {},
   "source": [
    "# Content-based filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b9f471b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b0967fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "common_movies = ratings_df['movieId'].unique()\n",
    "filtered_movies_df = movies_df[movies_df['movieId'].isin(common_movies)]\n",
    "\n",
    "tfid = TfidfVectorizer(stop_words='english')\n",
    "matrix = tfid.fit_transform(filtered_movies_df['features'])\n",
    "cosine_sim = cosine_similarity(matrix, matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f4ef7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_matrix = ratings_df.pivot(index='userId', columns='movieId', values='centered_rating')\n",
    "num_users = ratings_matrix.shape[0]\n",
    "num_items = ratings_matrix.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "39d5cc74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similar_users(cosine_sim, user_index, num_similar=5):\n",
    "    \"\"\"Get the top similar users based on cosine similarity.\"\"\"\n",
    "    similar_indices = cosine_sim[user_index].argsort()[-num_similar-1:-1][::-1] \n",
    "    return similar_indices\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b145ac8",
   "metadata": {},
   "source": [
    "# Collaborative filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4b840af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MatrixFactorizationWithBias:\n",
    "    def __init__(self, R, k, alpha, lambda_reg, num_epochs, tolerance=1e-4):\n",
    "        self.R = R\n",
    "        self.num_users, self.num_items = R.shape\n",
    "        self.k = k\n",
    "        self.alpha = alpha\n",
    "        self.lambda_reg = lambda_reg\n",
    "        self.num_epochs = num_epochs\n",
    "        self.tolerance = tolerance\n",
    "        \n",
    "        \n",
    "        # Uniform initialization\n",
    "        self.U = np.random.uniform(low=-0.01, high=0.01, size=(self.num_users, k))\n",
    "        self.V = np.random.uniform(low=-0.01, high=0.01, size=(self.num_items, k))\n",
    "\n",
    "    def train(self):\n",
    "        previous_mse = float('inf')\n",
    "        for epoch in range(self.num_epochs):\n",
    "            self.gradient_descent()\n",
    "            mse = self.compute_error()\n",
    "            print(f\"Epoch: {epoch + 1}, MSE: {mse:.4f}\")\n",
    "\n",
    "            if abs(previous_mse - mse) < self.tolerance:\n",
    "                print(\"Convergence reached.\")\n",
    "                break\n",
    "            previous_mse = mse\n",
    "\n",
    "    def gradient_descent(self):\n",
    "        S = np.argwhere(~np.isnan(self.R))\n",
    "        for i, j in S:\n",
    "            prediction = self.predict(i, j)\n",
    "            eij = self.R[i, j] - prediction\n",
    "            \n",
    "            if np.isnan(eij):\n",
    "                print(f\"NaN error found for user {i}, item {j}. Prediction: {prediction}, Rating: {self.R[i, j]}\")\n",
    "                continue\n",
    "\n",
    "            for q in range(self.k):\n",
    "                update_U = self.alpha * (eij * self.V[j, q] - self.lambda_reg * self.U[i, q])\n",
    "                update_V = self.alpha * (eij * self.U[i, q] - self.lambda_reg * self.V[j, q])\n",
    "\n",
    "                if np.isnan(update_U) or np.isnan(update_V):\n",
    "                    print(f\"NaN update for user {i}, item {j}, latent factor {q}: update_U: {update_U}, update_V: {update_V}\")\n",
    "                    continue\n",
    "\n",
    "                self.U[i, q] += update_U\n",
    "                self.V[j, q] += update_V\n",
    "\n",
    "    def predict(self, i, j):\n",
    "        return np.dot(self.U[i], self.V[j])\n",
    "\n",
    "    def compute_error(self):\n",
    "        xs, ys = np.argwhere(~np.isnan(self.R)).T\n",
    "        predicted = np.array([self.predict(i, j) for i, j in zip(xs, ys)])\n",
    "        observed_ratings = self.R[xs, ys]\n",
    "\n",
    "        if np.any(np.isnan(predicted)) or np.any(np.isnan(observed_ratings)):\n",
    "            print(\"NaN found in predictions or observed ratings.\")\n",
    "\n",
    "        error = np.sum((observed_ratings - predicted) ** 2)\n",
    "        return np.sqrt(error / len(xs)) if len(xs) > 0 else float('nan')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff5a28b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ratings_matrix(df):\n",
    "    return df.pivot(index='userId', columns='movieId', values='centered_rating')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1864fa8",
   "metadata": {},
   "source": [
    "The structure of a rating matrix differs from traditional machine learning tasks, where you typically have clear dependent (target) and independent (feature) variables. In a rating matrix, there isn't a straightforward distinction between these two. Instead, the matrix contains user-item interactions (like movie ratings), where each entry represents a user's rating for an item. This makes it challenging to directly apply typical machine learning techniques.\n",
    "\n",
    "To evaluate the model's performance, a common approach used in recommender systems is the hold-out method. In this method, a portion of the ratings is \"hidden\" or set aside as a test set, while the remaining ratings are used for training the model. The hidden ratings are then used to check how well the model can predict unseen data, allowing for a more realistic assessment of its accuracy in making recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4440bd6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data_holdout_entry_based(ratings_matrix, test_fraction=0.2):\n",
    "    R = ratings_matrix.values.copy()  \n",
    "\n",
    "    observed_indices = np.array(np.where(~np.isnan(R))).T\n",
    "    np.random.shuffle(observed_indices)\n",
    "    \n",
    "    num_test = int(len(observed_indices) * test_fraction)\n",
    "    \n",
    "    test_indices = observed_indices[:num_test]\n",
    "    train_indices = observed_indices[num_test:]\n",
    "    \n",
    "    R_train = R.copy()\n",
    "    R_test = np.full(R.shape, np.nan)\n",
    "\n",
    "    for idx in test_indices:\n",
    "        i, j = idx\n",
    "        R_test[i, j] = R[i, j] \n",
    "        R_train[i, j] = np.nan  \n",
    "    \n",
    "    print(\"Original Data Size:\", R.shape)\n",
    "    print(\"Training Set Size:\", np.sum(~np.isnan(R_train)))\n",
    "    print(\"Test Set Size:\", np.sum(~np.isnan(R_test)))\n",
    "    \n",
    "    return R_train, R_test, test_indices  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5ecaaf",
   "metadata": {},
   "source": [
    "to double check the split data by hold out method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8f42f6a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data Size: (69878, 10677)\n",
      "Training Set Size: 8000044\n",
      "Test Set Size: 2000010\n"
     ]
    }
   ],
   "source": [
    "pivot_rating_df = create_ratings_matrix(ratings_df)\n",
    "R_train, R_test, test_indices = split_data_holdout_entry_based(pivot_rating_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6d36cfc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data Size: (10000054, 5)\n",
      "Training Set Size: 8000044\n",
      "Test Set Size: 2000010\n",
      "Number of overlapping entries: 0\n",
      "Test ratings found in training set: 0\n",
      "Coverage in Training Set: 0.007492742156032294 %\n",
      "Coverage in Test Set: 0.001873184602420455 %\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.DataFrame(R_train, index=pivot_rating_df.index, columns=pivot_rating_df.columns)\n",
    "test_df = pd.DataFrame(R_test, index=pivot_rating_df.index, columns=pivot_rating_df.columns)\n",
    "\n",
    "print(\"Original Data Size:\", ratings_df.shape)\n",
    "print(\"Training Set Size:\", train_df.count().sum())\n",
    "print(\"Test Set Size:\", test_df.count().sum())\n",
    "\n",
    "\n",
    "overlap = np.where(~np.isnan(R_train) & ~np.isnan(R_test))\n",
    "print(\"Number of overlapping entries:\", len(overlap[0]))\n",
    "\n",
    "train_ratings = train_df.stack().reset_index()\n",
    "test_ratings = test_df.stack().reset_index() \n",
    "\n",
    "test_in_train = test_ratings[test_ratings[['userId', 'movieId']].apply(tuple, axis=1).isin(train_ratings[['userId', 'movieId']].apply(tuple, axis=1))]\n",
    "print(\"Test ratings found in training set:\", len(test_in_train))\n",
    "\n",
    "print(\"Coverage in Training Set:\", len(train_ratings) / (len(ratings_df) * len(pivot_rating_df.columns)) * 100, \"%\")\n",
    "print(\"Coverage in Test Set:\", len(test_ratings) / (len(ratings_df) * len(pivot_rating_df.columns)) * 100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa381bd",
   "metadata": {},
   "source": [
    "In the model, latent factors (k), learning rate (alpha), and Regularization (lambda) are the hypeparameters in the model. \n",
    "<br>Small k, high lambda, small alpha = High bias, low variance (underfitting).\n",
    "<br>Large k, low lambda, large alpha = Low bias, high variance (overfitting)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cab94f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rmse(predictions, actuals):\n",
    "    mse = np.mean((predictions - actuals) ** 2)\n",
    "    return np.sqrt(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b3024f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperparameter_tuning(ratings_matrix, param_grid, test_fraction=0.2, num_epochs=10):\n",
    "    \n",
    "    R_train, R_test, test_indices = split_data_holdout_entry_based(ratings_matrix, test_fraction)\n",
    "    \n",
    "    best_rmse = float('inf')\n",
    "    best_params = {}\n",
    "    \n",
    "    for k in param_grid['k']:\n",
    "        for alpha in param_grid['alpha']:\n",
    "            for lambda_reg in param_grid['lambda_reg']:\n",
    "                print(f\"Testing k={k}, alpha={alpha}, lambda_reg={lambda_reg}\")\n",
    "\n",
    "                mf_model = MatrixFactorizationWithBias(R_train, k=k, alpha=alpha, lambda_reg=lambda_reg, num_epochs=num_epochs)\n",
    "                mf_model.train() \n",
    "\n",
    "                test_predictions = []\n",
    "                for i, j in test_indices:\n",
    "                    if not np.isnan(R_test[i, j]):  \n",
    "                        prediction = mf_model.predict(i, j)\n",
    "                        test_predictions.append(prediction)\n",
    "\n",
    "                actuals = R_test[test_indices[:, 0], test_indices[:, 1]]\n",
    "\n",
    "                if len(test_predictions) > 0:\n",
    "                    rmse = calculate_rmse(np.array(test_predictions), actuals)\n",
    "                else:\n",
    "                    print(\"No predictions were made.\")\n",
    "                    rmse = float('nan')\n",
    "\n",
    "                print(f\"Validation RMSE: {rmse:.4f}\")\n",
    "\n",
    "                if rmse < best_rmse:\n",
    "                    best_rmse = rmse\n",
    "                    best_params = {'k': k, 'alpha': alpha, 'lambda_reg': lambda_reg}\n",
    "\n",
    "    print(\"Best Parameters:\")\n",
    "    print(best_params)\n",
    "    print(f\"Best Validation RMSE: {best_rmse:.4f}\")\n",
    "    \n",
    "    return best_params, best_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b2f7df2",
   "metadata": {},
   "source": [
    "The relationship between k (latent factors), alpha (learning rate), and lambda_reg (regularization) is simple:\n",
    "\n",
    "k (Latent Factors): Increasing k improves the model's accuracy by capturing more patterns, but the benefits decrease as k gets larger, making the model slower to train.\n",
    "\n",
    "alpha (Learning Rate): A higher alpha helps the model learn faster but can cause instability at the start. A moderate alpha balances speed and stability.\n",
    "\n",
    "lambda_reg (Regularization): Regularization prevents the model from overfitting by limiting complexity. A steady value of lambda_reg keeps the model stable across different settings of k and alpha.\n",
    "\n",
    "Together, k controls complexity, alpha affects learning speed, and lambda_reg ensures stability. Finding the right balance leads to faster training and better predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2b2f69bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data Size: (69878, 10677)\n",
      "Training Set Size: 8000044\n",
      "Test Set Size: 2000010\n",
      "Testing k=10, alpha=0.001, lambda_reg=0.01\n",
      "Epoch: 1, MSE: 3.6538\n",
      "Epoch: 2, MSE: 2.5484\n",
      "Epoch: 3, MSE: 1.5877\n",
      "Epoch: 4, MSE: 1.2825\n",
      "Epoch: 5, MSE: 1.1453\n",
      "Epoch: 6, MSE: 1.0678\n",
      "Epoch: 7, MSE: 1.0187\n",
      "Epoch: 8, MSE: 0.9851\n",
      "Epoch: 9, MSE: 0.9610\n",
      "Epoch: 10, MSE: 0.9429\n",
      "Validation RMSE: 0.9530\n",
      "Testing k=10, alpha=0.005, lambda_reg=0.01\n",
      "Epoch: 1, MSE: 3.5456\n",
      "Epoch: 2, MSE: 1.2885\n",
      "Epoch: 3, MSE: 1.0136\n",
      "Epoch: 4, MSE: 0.9421\n",
      "Epoch: 5, MSE: 0.9071\n",
      "Epoch: 6, MSE: 0.8827\n",
      "Epoch: 7, MSE: 0.8628\n",
      "Epoch: 8, MSE: 0.8462\n",
      "Epoch: 9, MSE: 0.8319\n",
      "Epoch: 10, MSE: 0.8200\n",
      "Validation RMSE: 0.8464\n",
      "Testing k=10, alpha=0.009, lambda_reg=0.01\n",
      "Epoch: 1, MSE: 3.8158\n",
      "Epoch: 2, MSE: 1.5054\n",
      "Epoch: 3, MSE: 1.0083\n",
      "Epoch: 4, MSE: 0.9156\n",
      "Epoch: 5, MSE: 0.8718\n",
      "Epoch: 6, MSE: 0.8442\n",
      "Epoch: 7, MSE: 0.8242\n",
      "Epoch: 8, MSE: 0.8085\n",
      "Epoch: 9, MSE: 0.7965\n",
      "Epoch: 10, MSE: 0.7874\n",
      "Validation RMSE: 0.8309\n",
      "Testing k=20, alpha=0.001, lambda_reg=0.01\n",
      "Epoch: 1, MSE: 3.6499\n",
      "Epoch: 2, MSE: 2.5022\n",
      "Epoch: 3, MSE: 1.5732\n",
      "Epoch: 4, MSE: 1.2757\n",
      "Epoch: 5, MSE: 1.1398\n",
      "Epoch: 6, MSE: 1.0624\n",
      "Epoch: 7, MSE: 1.0129\n",
      "Epoch: 8, MSE: 0.9789\n",
      "Epoch: 9, MSE: 0.9545\n",
      "Epoch: 10, MSE: 0.9363\n",
      "Validation RMSE: 0.9469\n",
      "Testing k=20, alpha=0.005, lambda_reg=0.01\n",
      "Epoch: 1, MSE: 3.6603\n",
      "Epoch: 2, MSE: 1.3659\n",
      "Epoch: 3, MSE: 1.0197\n",
      "Epoch: 4, MSE: 0.9412\n",
      "Epoch: 5, MSE: 0.9007\n",
      "Epoch: 6, MSE: 0.8733\n",
      "Epoch: 7, MSE: 0.8527\n",
      "Epoch: 8, MSE: 0.8357\n",
      "Epoch: 9, MSE: 0.8219\n",
      "Epoch: 10, MSE: 0.8105\n",
      "Validation RMSE: 0.8390\n",
      "Testing k=20, alpha=0.009, lambda_reg=0.01\n",
      "Epoch: 1, MSE: 3.4786\n",
      "Epoch: 2, MSE: 1.1979\n",
      "Epoch: 3, MSE: 0.9461\n",
      "Epoch: 4, MSE: 0.8849\n",
      "Epoch: 5, MSE: 0.8498\n",
      "Epoch: 6, MSE: 0.8254\n",
      "Epoch: 7, MSE: 0.8067\n",
      "Epoch: 8, MSE: 0.7917\n",
      "Epoch: 9, MSE: 0.7788\n",
      "Epoch: 10, MSE: 0.7673\n",
      "Validation RMSE: 0.8197\n",
      "Testing k=30, alpha=0.001, lambda_reg=0.01\n",
      "Epoch: 1, MSE: 3.6354\n",
      "Epoch: 2, MSE: 2.3873\n",
      "Epoch: 3, MSE: 1.5386\n",
      "Epoch: 4, MSE: 1.2624\n",
      "Epoch: 5, MSE: 1.1331\n",
      "Epoch: 6, MSE: 1.0585\n",
      "Epoch: 7, MSE: 1.0106\n",
      "Epoch: 8, MSE: 0.9776\n",
      "Epoch: 9, MSE: 0.9537\n",
      "Epoch: 10, MSE: 0.9359\n",
      "Validation RMSE: 0.9464\n",
      "Testing k=30, alpha=0.005, lambda_reg=0.01\n",
      "Epoch: 1, MSE: 3.5748\n",
      "Epoch: 2, MSE: 1.2948\n",
      "Epoch: 3, MSE: 1.0087\n",
      "Epoch: 4, MSE: 0.9361\n",
      "Epoch: 5, MSE: 0.8966\n",
      "Epoch: 6, MSE: 0.8693\n",
      "Epoch: 7, MSE: 0.8485\n",
      "Epoch: 8, MSE: 0.8321\n",
      "Epoch: 9, MSE: 0.8190\n",
      "Epoch: 10, MSE: 0.8079\n",
      "Validation RMSE: 0.8373\n",
      "Testing k=30, alpha=0.009, lambda_reg=0.01\n",
      "Epoch: 1, MSE: 3.5510\n",
      "Epoch: 2, MSE: 1.2270\n",
      "Epoch: 3, MSE: 0.9509\n",
      "Epoch: 4, MSE: 0.8858\n",
      "Epoch: 5, MSE: 0.8504\n",
      "Epoch: 6, MSE: 0.8263\n",
      "Epoch: 7, MSE: 0.8072\n",
      "Epoch: 8, MSE: 0.7908\n",
      "Epoch: 9, MSE: 0.7758\n",
      "Epoch: 10, MSE: 0.7621\n",
      "Validation RMSE: 0.8183\n",
      "Testing k=50, alpha=0.001, lambda_reg=0.01\n",
      "Epoch: 1, MSE: 3.6347\n",
      "Epoch: 2, MSE: 2.3840\n",
      "Epoch: 3, MSE: 1.5368\n",
      "Epoch: 4, MSE: 1.2600\n",
      "Epoch: 5, MSE: 1.1295\n",
      "Epoch: 6, MSE: 1.0541\n",
      "Epoch: 7, MSE: 1.0058\n",
      "Epoch: 8, MSE: 0.9727\n",
      "Epoch: 9, MSE: 0.9491\n",
      "Epoch: 10, MSE: 0.9317\n",
      "Validation RMSE: 0.9425\n",
      "Testing k=50, alpha=0.005, lambda_reg=0.01\n",
      "Epoch: 1, MSE: 3.6050\n",
      "Epoch: 2, MSE: 1.2990\n",
      "Epoch: 3, MSE: 1.0045\n",
      "Epoch: 4, MSE: 0.9315\n",
      "Epoch: 5, MSE: 0.8918\n",
      "Epoch: 6, MSE: 0.8651\n",
      "Epoch: 7, MSE: 0.8446\n",
      "Epoch: 8, MSE: 0.8283\n",
      "Epoch: 9, MSE: 0.8151\n",
      "Epoch: 10, MSE: 0.8037\n",
      "Validation RMSE: 0.8344\n",
      "Testing k=50, alpha=0.009, lambda_reg=0.01\n",
      "Epoch: 1, MSE: 3.5905\n",
      "Epoch: 2, MSE: 1.2306\n",
      "Epoch: 3, MSE: 0.9477\n",
      "Epoch: 4, MSE: 0.8817\n",
      "Epoch: 5, MSE: 0.8459\n",
      "Epoch: 6, MSE: 0.8214\n",
      "Epoch: 7, MSE: 0.8016\n",
      "Epoch: 8, MSE: 0.7842\n",
      "Epoch: 9, MSE: 0.7681\n",
      "Epoch: 10, MSE: 0.7526\n",
      "Validation RMSE: 0.8148\n",
      "Best Parameters:\n",
      "{'k': 50, 'alpha': 0.009, 'lambda_reg': 0.01}\n",
      "Best Validation RMSE: 0.8148\n"
     ]
    }
   ],
   "source": [
    "# Define the hyperparameter grid\n",
    "param_grid = {\n",
    "    'k': [10, 20, 30, 50],  # Smaller dimensions for faster training\n",
    "    'alpha': [0.001, 0.005, 0.009],  # Higher learning rate to speed up convergence\n",
    "    'lambda_reg': [0.01]  # Smaller regularization to limit the impact of regularization\n",
    "}\n",
    "\n",
    "best_params, best_rmse = hyperparameter_tuning(ratings_matrix, param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab083e9",
   "metadata": {},
   "source": [
    "In this experiment, different values of k (the number of latent factors), alpha (learning rate), and lambda_reg (regularization strength) are tested to observe how they affect the error (measured by Mean Squared Error, MSE) and model performance (Validation RMSE).\n",
    "\n",
    "Learning rate (alpha): As the learning rate increases (from 0.001 to 0.009), the model converges more quickly, meaning the error decreases faster. However, if the learning rate is too high (e.g., 0.009), the initial MSE starts higher, but the model still achieves a lower final error.\n",
    "\n",
    "Number of latent factors (k): Increasing k (from 10 to 50) slightly improves performance, as shown by lower Validation RMSE, but the improvement becomes smaller at higher values of k.\n",
    "\n",
    "Stability of errors: The MSE tends to decrease steadily over epochs, regardless of the parameter combination. For higher values of k and alpha, the final Validation RMSE improves, meaning better prediction accuracy.\n",
    "\n",
    "Overall, alpha = 0.009 and k = 30 or 50 seem to provide the best balance between fast convergence and low error. Regularization (lambda_reg = 0.01) is kept constant and appears to help maintain stability without overfitting. \n",
    "\n",
    "Collaborative filtering alone is already performing well (as indicated by a low MSE), adding content-based filtering may not significantly improve performance. If the content-based model is more complex or trained on the same data, it may lead to overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0194cd65",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetaHybridRecommender:\n",
    "    def __init__(self, ratings_matrix, cosine_sim, k, alpha, lambda_reg, num_epochs):\n",
    "        self.ratings_matrix = ratings_matrix\n",
    "        self.cosine_sim = cosine_sim\n",
    "        self.cf_model = MatrixFactorizationWithBias(ratings_matrix, k, alpha, lambda_reg, num_epochs)\n",
    "        \n",
    "    def train(self):\n",
    "        self.cf_model.train()\n",
    "\n",
    "    def recommend_all_users(self, num_recommendations=5):\n",
    "        \n",
    "        cf_predictions = self.cf_model.predict_all_users()\n",
    "\n",
    "        all_recommendations = []\n",
    "        for user_id in range(self.ratings_matrix.shape[0]):\n",
    "           \n",
    "            content_predictions = self.get_content_based_recommendations(user_id)\n",
    "\n",
    "            combined_predictions = self.combine_predictions(cf_predictions[user_id], content_predictions)\n",
    "\n",
    "            recommended_indices = np.argsort(combined_predictions)[::-1][:num_recommendations]\n",
    "            all_recommendations.append(recommended_indices)\n",
    "\n",
    "        return all_recommendations\n",
    "\n",
    "    def get_content_based_recommendations(self, user_id):\n",
    "        \n",
    "        user_ratings = self.ratings_matrix[user_id]\n",
    "        rated_indices = np.argwhere(~np.isnan(user_ratings)).flatten()\n",
    "\n",
    "        \n",
    "        weighted_scores = np.zeros(self.ratings_matrix.shape[1])\n",
    "        for idx in rated_indices:\n",
    "            sim_scores = self.cosine_sim[idx]\n",
    "            weighted_scores += sim_scores * user_ratings[idx]\n",
    "\n",
    "        \n",
    "        weighted_scores /= len(rated_indices) if len(rated_indices) > 0 else 1\n",
    "        return weighted_scores\n",
    "\n",
    "    def combine_predictions(self, cf_scores, content_scores, cf_weight=0.5, content_weight=0.5):\n",
    "        return (cf_weight * cf_scores) + (content_weight * content_scores)\n",
    "\n",
    "    def predict_all_users(self):\n",
    "      \n",
    "        return np.array([self.cf_model.predict(i, j) for i in range(self.ratings_matrix.shape[0]) for j in range(self.ratings_matrix.shape[1])]).reshape(self.ratings_matrix.shape)\n",
    "\n",
    "    def compute_mse_rmse(self):\n",
    "       \n",
    "        predicted_ratings = self.predict_all_users()\n",
    "\n",
    "        actual_ratings = self.ratings_matrix.flatten()\n",
    "        predicted_ratings = predicted_ratings.flatten()\n",
    "\n",
    "        mse = np.mean((actual_ratings - predicted_ratings) ** 2)\n",
    "\n",
    "  \n",
    "        rmse = np.sqrt(mse)\n",
    "\n",
    "        return mse, rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86b0c0a",
   "metadata": {},
   "source": [
    "Due to the limitation for computational resouces and data resources, it leads tp overfitting when combining with content-based recommender system."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
